{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "machine-trainslation.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "R9TvxEMOfadt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Machine Translation using Applied Deep Learning (RNN)"
      ]
    },
    {
      "metadata": {
        "id": "kCbieYQ9Z60U",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Setting everything up."
      ]
    },
    {
      "metadata": {
        "id": "tGWowqcsBxZ6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install -q tensorflow-gpu==2.0.0-alpha0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8b58W7TCB0Ca",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "outputId": "62ff926b-d077-442c-d068-9a050fb2cc44"
      },
      "cell_type": "code",
      "source": [
        "!pip install sacrebleu # https://github.com/mjpost/sacreBLEU"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sacrebleu in /usr/local/lib/python3.6/dist-packages (1.3.2)\n",
            "Requirement already satisfied: typing in /usr/local/lib/python3.6/dist-packages (from sacrebleu) (3.6.6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "20_JzOBNLQKF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# importing necessary packages\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import sacrebleu\n",
        "import tensorflow as tf\n",
        "import time\n",
        "import unicodedata"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pcuEduUqf4Ec",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## English to Spanish Model\n",
        "Training a model to translate between two languages (from English to Spanish) using a couple thousand sentences. \n",
        "\n",
        "First, we read in the txt file with a number of spanish-english translations available."
      ]
    },
    {
      "metadata": {
        "id": "pWTdbrqyD3Sh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "outputId": "3dce416c-235a-48a9-c503-ff9aff0caef0"
      },
      "cell_type": "code",
      "source": [
        "# reading in the spanish-english dataset\n",
        "data = pd.read_csv('spa.txt', delimiter=\"\\t\", header=None, names=['eng_sen', 'spa_sen'])\n",
        "# randomly selecting 2 thousand sentences for the working dataset\n",
        "data_sub = data.sample(n=2000)\n",
        "# looking into the subset\n",
        "data_sub.head(3)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>eng_sen</th>\n",
              "      <th>spa_sen</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>92457</th>\n",
              "      <td>For more information, visit our website.</td>\n",
              "      <td>Para más información, visite nuestro sitio.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78484</th>\n",
              "      <td>When in Rome, do as the Romans do.</td>\n",
              "      <td>Allá donde fueres, haz lo que vieres.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54463</th>\n",
              "      <td>This song's in the key of G.</td>\n",
              "      <td>Esta canción está en clave de sol.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                        eng_sen  \\\n",
              "92457  For more information, visit our website.   \n",
              "78484        When in Rome, do as the Romans do.   \n",
              "54463              This song's in the key of G.   \n",
              "\n",
              "                                           spa_sen  \n",
              "92457  Para más información, visite nuestro sitio.  \n",
              "78484        Allá donde fueres, haz lo que vieres.  \n",
              "54463           Esta canción está en clave de sol.  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "vN3MqDMe3_qY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_indexes = data_sub.index.tolist()\n",
        "data_test = data.drop(data.index[train_indexes])\n",
        "data_test = data_test.sample(n=1000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BQcNy0yDHl5u",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# convering the dataframe into a list representation\n",
        "sentences = data_sub.values.tolist()\n",
        "sentences_test = data_test.values.tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "y3N8RENdaIzl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Next, we apply the necessary data preprocessing."
      ]
    },
    {
      "metadata": {
        "id": "dEBzbO9QLXJY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def preprocess(s):\n",
        "  # for details, see https://www.tensorflow.org/alpha/tutorials/sequences/nmt_with_attention\n",
        "  s = ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')\n",
        "  s = re.sub(r\"([?.!,¿])\", r\" \\1 \", s)\n",
        "  s = re.sub(r'[\" \"]+', \" \", s)\n",
        "  s = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", s)\n",
        "  s = s.strip()\n",
        "  s = '<start> ' + s + ' <end>'\n",
        "  return s"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "stKYfGo2LZ89",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "outputId": "c5622a29-c9c1-413a-9a4f-e2281fc77fb8"
      },
      "cell_type": "code",
      "source": [
        "# looking into what preprocessing does exactly\n",
        "print(\"Original:\", sentences[0])\n",
        "sentences = [(preprocess(source), preprocess(target)) for (source, target) in sentences]\n",
        "sentences_test = [(preprocess(source), preprocess(target)) for (source, target) in sentences_test]\n",
        "print(\"Preprocessed:\", sentences[0])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original: ['For more information, visit our website.', 'Para más información, visite nuestro sitio.']\n",
            "Preprocessed: ('<start> For more information , visit our website . <end>', '<start> Para mas informacion , visite nuestro sitio . <end>')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "IWFGZ4tLLZ_e",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# creating a target and source zip view\n",
        "source_sentences, target_sentences = list(zip(*sentences))\n",
        "\n",
        "source_sentences_test, target_sentences_test = list(zip(*sentences_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kRv1SEn8LaB0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "b00503f3-a17a-43c6-9fa1-8182af2245a1"
      },
      "cell_type": "code",
      "source": [
        "# fitting tokenization\n",
        "source_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='', oov_token='outofvocab')\n",
        "source_tokenizer.fit_on_texts(source_sentences)\n",
        "source_data = source_tokenizer.texts_to_sequences(source_sentences)\n",
        "source_data_test = source_tokenizer.texts_to_sequences(source_sentences_test)\n",
        "print(\"Sequence:\", source_data[0])\n",
        "# adding some padding\n",
        "source_data = tf.keras.preprocessing.sequence.pad_sequences(source_data, padding='post')\n",
        "source_data_test = tf.keras.preprocessing.sequence.pad_sequences(source_data_test, padding='post')\n",
        "print(\"Padded:\", source_data[0])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequence: [2, 29, 76, 639, 21, 286, 112, 966, 4, 3]\n",
            "Padded: [  2  29  76 639  21 286 112 966   4   3   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2mdvgn73LaES",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# do the same with target\n",
        "target_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='', oov_token='outofvocab')\n",
        "target_tokenizer.fit_on_texts(target_sentences)\n",
        "target_data = target_tokenizer.texts_to_sequences(target_sentences)\n",
        "target_data = tf.keras.preprocessing.sequence.pad_sequences(target_data, padding='post')\n",
        "target_data_test = target_tokenizer.texts_to_sequences(target_sentences_test)\n",
        "target_data_test = tf.keras.preprocessing.sequence.pad_sequences(target_data_test, padding='post')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mMkaoPb9LtyE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "a65c6444-f141-4682-f657-de6eb4594689"
      },
      "cell_type": "code",
      "source": [
        "# Create labels for the decoder by shifting the target sequence\n",
        "# one to the right.\n",
        "target_labels = np.zeros(target_data.shape)\n",
        "target_labels[:,0:target_data.shape[1] -1] = target_data[:,1:]\n",
        "\n",
        "target_labels_test = np.zeros(target_data_test.shape)\n",
        "target_labels_test[:,0:target_data_test.shape[1] -1] = target_data_test[:,1:]\n",
        "\n",
        "print(\"Target sequence\", target_data[0])\n",
        "print(\"Target label\", target_labels[0])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Target sequence [  2  30  31 637  20 445 186 368   4   3   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0]\n",
            "Target label [ 30.  31. 637.  20. 445. 186. 368.   4.   3.   0.   0.   0.   0.   0.\n",
            "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "   0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PtIHP9pJLxFe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "source_vocab_size = len(source_tokenizer.word_index) + 1\n",
        "target_vocab_size = len(target_tokenizer.word_index) + 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jpU3VIglLzhM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "8373dfe5-8aa3-4ccd-89ee-b971331206ac"
      },
      "cell_type": "code",
      "source": [
        "def decode(encoded, tokenizer):\n",
        "  for number in encoded:\n",
        "    if number !=0:\n",
        "      print (\"%d -> %s\" % (number, tokenizer.index_word[number]))\n",
        "      \n",
        "decode(source_data[0], source_tokenizer)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2 -> <start>\n",
            "29 -> for\n",
            "76 -> more\n",
            "639 -> information\n",
            "21 -> ,\n",
            "286 -> visit\n",
            "112 -> our\n",
            "966 -> website\n",
            "4 -> .\n",
            "3 -> <end>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kpLWzduwaWvq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "I chose the batch size to be 16 instead of 5 based on the advanced tutorial documentation (they are using 56 there)."
      ]
    },
    {
      "metadata": {
        "id": "SJrKLzLlLzjw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "dataset = tf.data.Dataset.from_tensor_slices((source_data, target_data, target_labels)).batch(batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-Nt5ubEZLzl2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6e7f7c1d-7c9d-4652-a1d6-48274dd44736"
      },
      "cell_type": "code",
      "source": [
        "# looking at a specific example\n",
        "example_batch = next(iter(dataset))\n",
        "source, target, taget_labels = example_batch\n",
        "print(\"Shapes:\", source.shape, target.shape, taget_labels.shape)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shapes: (16, 30) (16, 29) (16, 29)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "b7u9dNfFafmF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "For the RNN model, I have settled on 128 depth guided by the advanced documentation as well (their default in actually 1024). In addition, the embedding size is set to 256."
      ]
    },
    {
      "metadata": {
        "id": "bVpaNsfSL4Ld",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# choosing our parameters\n",
        "embedding_size = 256\n",
        "rnn_size = 128"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7priMAcML4N5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "  def __init__(self):\n",
        "    super(Encoder, self).__init__()\n",
        "    \n",
        "    self.embedding = tf.keras.layers.Embedding(source_vocab_size,\n",
        "                                               embedding_size)\n",
        "    self.gru = tf.keras.layers.GRU(rnn_size, \n",
        "                                   return_sequences=True, \n",
        "                                   return_state=True)\n",
        "    \n",
        "  def call(self, x, hidden):\n",
        "    x = self.embedding(x)\n",
        "    output, state = self.gru(x, initial_state=hidden)        \n",
        "    return output, state\n",
        "  \n",
        "  def init_state(self, batch_size):\n",
        "    return tf.zeros((batch_size, rnn_size))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iO9UQXxFL4QV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "756e5e43-679a-4357-f910-b20df67076df"
      },
      "cell_type": "code",
      "source": [
        "# Create a batch of one sentence\n",
        "ex_sentence = tf.expand_dims(source_data[0], axis=0)\n",
        "ex_translation = tf.expand_dims(target_data[0], axis=0)\n",
        "ex_labels = tf.expand_dims(target_labels[0], axis=0)\n",
        "print(ex_sentence.shape)\n",
        "\n",
        "encoder = Encoder()\n",
        "hidden_state = encoder.init_state(batch_size=1)\n",
        "print(hidden_state.shape)\n",
        "\n",
        "output, hidden_state = encoder(ex_sentence, hidden_state)\n",
        "print(output.shape)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 30)\n",
            "(1, 128)\n",
            "(1, 30, 128)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "aTIEqT29L9d5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "  def __init__(self):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.embedding = tf.keras.layers.Embedding(target_vocab_size, \n",
        "                                               embedding_size)\n",
        "    self.gru = tf.keras.layers.GRU(rnn_size, \n",
        "                                   return_sequences=True, \n",
        "                                   return_state=True)\n",
        "\n",
        "    self.dense = tf.keras.layers.Dense(target_vocab_size)\n",
        "\n",
        "\n",
        "  def call(self, x, hidden):\n",
        "    x = self.embedding(x)\n",
        "    output, state = self.gru(x, initial_state=hidden)\n",
        "    logits = self.dense(output)\n",
        "    return logits, state"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "afGG3KwDL9ge",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4e84b6ae-b7d1-42e7-d978-d74c7a2c8a21"
      },
      "cell_type": "code",
      "source": [
        "# calling the decoder\n",
        "decoder = Decoder()\n",
        "decoder_output, decoder_state = decoder(ex_labels, hidden_state)\n",
        "print(decoder_output.shape)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 29, 2846)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Ax66BIcrMB_9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "444052d7-ceac-4149-93ab-d509c4f66b3b"
      },
      "cell_type": "code",
      "source": [
        "crossentropy = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "def calc_loss(targets, logits):\n",
        "  mask = tf.math.logical_not(tf.math.equal(targets, 0))\n",
        "  mask = tf.cast(mask, dtype=tf.int64)\n",
        "  return crossentropy(targets, logits, sample_weight=mask)\n",
        "\n",
        "print(\"Loss\", calc_loss(ex_labels, decoder_output))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss tf.Tensor(2.4681187, shape=(), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lL9zEiPiMCCL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def translate(sentences, source_data, idx=None):\n",
        "  \n",
        "    if idx == None: \n",
        "      idx = np.random.choice(len(sentences))\n",
        "    \n",
        "    input_sent = source_data[idx]\n",
        "    input_sent = tf.expand_dims(input_sent, axis=0)\n",
        "    \n",
        "    hidden_state = encoder.init_state(batch_size=1)\n",
        "    output, hidden_state = encoder(input_sent, hidden_state)\n",
        "    \n",
        "    decoder_input = tf.expand_dims([target_tokenizer.word_index['<start>']], 0)\n",
        "    out_words = []\n",
        "    \n",
        "    decoder_state = hidden_state\n",
        "\n",
        "    while True:\n",
        "      \n",
        "        decoder_output, decoder_state = decoder(decoder_input, decoder_state)\n",
        "        decoder_input = tf.argmax(decoder_output, -1)\n",
        "        word_idx = decoder_input.numpy()[0][0]\n",
        "        # if we've predicted 0 (which is reserved, usually this will only happen\n",
        "        # before the decoder is trained, just stop translating and return\n",
        "        # what we have)\n",
        "        if word_idx == 0: \n",
        "          out_words.append('<end>')\n",
        "        else:\n",
        "          out_words.append(target_tokenizer.index_word[word_idx])\n",
        "\n",
        "        if out_words[-1] == '<end>' or len(out_words) >= 20:\n",
        "          break\n",
        "          \n",
        "    translation = ' '.join(out_words)    \n",
        "    return sentences[idx][0], sentences[idx][1], translation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2SpwqEh6MLie",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "outputId": "2f1332df-4774-4a98-d3ba-3639d64810ac"
      },
      "cell_type": "code",
      "source": [
        "input_sent, target_sent, translation = translate(sentences, source_data)\n",
        "print(\"Input: %s\\nTarget: %s\\nTranslation: %s\\n\" % (input_sent, target_sent, translation))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: <start> Do you have an alarm clock in your room ? <end>\n",
            "Target: <start> ¿ Tienes despertador en tu dormitorio ? <end>\n",
            "Translation: sente subirse investigacion haga dieron perdisteis casada asi dolares cena atrapar perdisteis casada hijos tratado fatigas pintores hasta anciano tus\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FSlqHXo2atvS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Since we have not yet trained our model, the translation looks pretty crazy and impossible to comprehend (to be expected though). Nonetheless, we expect that to change once the model is trained. Therefore, let us train the model."
      ]
    },
    {
      "metadata": {
        "id": "TxFF2T92MLlB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.Adam()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pkuhrzynMLnR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "@tf.function # remove this annotation when debugging\n",
        "def train_step(source_seq, target_seq, target_labels, initial_state):\n",
        "  \n",
        "  with tf.GradientTape() as tape:\n",
        "    encoder_output, encoder_state = encoder(source_seq, initial_state)\n",
        "    logits, decoder_state = decoder(target_seq, encoder_state)\n",
        "    loss = calc_loss(target_labels, logits)\n",
        "\n",
        "  variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "  gradients = tape.gradient(loss, variables)\n",
        "  optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "  return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2u9iQZdcMSV-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 992
        },
        "outputId": "3643a380-e60b-4ca1-bc59-0359941f9f9a"
      },
      "cell_type": "code",
      "source": [
        "EPOCHS = 101\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    start = time.time()\n",
        "  \n",
        "    en_initial_states = encoder.init_state(batch_size)\n",
        "    \n",
        "    for batch, (source_seq, target_seq, target_labels) in enumerate(dataset):\n",
        "      loss = train_step(source_seq, target_seq, target_labels, en_initial_states)\n",
        "      elapsed = time.time() - start\n",
        "    \n",
        "    if epoch % 10 == 0:\n",
        "      print(\"Epoch #%d, Loss %.4f, Time %.2f sec\" % (epoch, loss, elapsed))\n",
        "      input_sent, target_sent, translation = translate(sentences, source_data)\n",
        "      print(\"Input: %s\\nTarget: %s\\nTranslation: %s\\n\" % (input_sent, target_sent, translation))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch #0, Loss 1.6153, Time 23.18 sec\n",
            "Input: <start> I ve waited for this too long . <end>\n",
            "Target: <start> He esperado demasiado tiempo para esto . <end>\n",
            "Translation: no no no . <end>\n",
            "\n",
            "Epoch #10, Loss 0.9153, Time 19.02 sec\n",
            "Input: <start> I don t have your number . <end>\n",
            "Target: <start> No tengo tu numero . <end>\n",
            "Translation: ¿ que es el unico que esta ? <end>\n",
            "\n",
            "Epoch #20, Loss 0.6159, Time 19.11 sec\n",
            "Input: <start> I came here to see if there was something I could do to help , but there doesn t seem to be anything for me to do . <end>\n",
            "Target: <start> Vine aqui para ver si habia algo que pudiera hacer para ayudar , pero parece que no hay nada para que yo haga . <end>\n",
            "Translation: ¿ que es el unico que esta pasando ? <end>\n",
            "\n",
            "Epoch #30, Loss 0.4169, Time 19.16 sec\n",
            "Input: <start> My neighbor s dog won t eat dry dog food . <end>\n",
            "Target: <start> El perro de mi vecino no come comida de perros seca . <end>\n",
            "Translation: el hombre confeso que el se dijo que se abstuviera de tomar vino . <end>\n",
            "\n",
            "Epoch #40, Loss 0.2872, Time 19.05 sec\n",
            "Input: <start> Are you free tomorrow afternoon ? <end>\n",
            "Target: <start> ¿ Estas libre manana por la tarde ? <end>\n",
            "Translation: ¿ estas dentro ? <end>\n",
            "\n",
            "Epoch #50, Loss 0.1979, Time 19.17 sec\n",
            "Input: <start> They said no . <end>\n",
            "Target: <start> Dijeron que no . <end>\n",
            "Translation: eso es justo lo que el auto no puede pasar . <end>\n",
            "\n",
            "Epoch #60, Loss 0.1378, Time 19.24 sec\n",
            "Input: <start> Last night s storm washed out the road . <end>\n",
            "Target: <start> El aguacero de anoche ha cortado el camino . <end>\n",
            "Translation: el aguacero de anoche ha cortado el camino . <end>\n",
            "\n",
            "Epoch #70, Loss 0.0952, Time 19.04 sec\n",
            "Input: <start> I have to go get it . <end>\n",
            "Target: <start> Tengo que ir a por ello . <end>\n",
            "Translation: tengo que hacer eso . <end>\n",
            "\n",
            "Epoch #80, Loss 0.0797, Time 18.94 sec\n",
            "Input: <start> I want you to meet my family . <end>\n",
            "Target: <start> Quiero que conozcas a mi familia . <end>\n",
            "Translation: quiero que nos dejen solos . <end>\n",
            "\n",
            "Epoch #90, Loss 0.0353, Time 18.71 sec\n",
            "Input: <start> I can t blame him . <end>\n",
            "Target: <start> No lo puedo culpar . <end>\n",
            "Translation: no me he sentido muy bien . <end>\n",
            "\n",
            "Epoch #100, Loss 0.0223, Time 19.08 sec\n",
            "Input: <start> She was beautiful when she was young . <end>\n",
            "Target: <start> Ella era hermosa cuando joven . <end>\n",
            "Translation: ella era hermosa cuando joven . <end>\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dwNw5zQ4MU7e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "9689a50c-b920-4dd7-dea0-7fc71d125f40"
      },
      "cell_type": "code",
      "source": [
        "# calculating BLEAU score\n",
        "references, hypotheses = [], []\n",
        "\n",
        "for i in range(len(sentences)):\n",
        "  input_sent, target_sent, translation = translate(sentences, source_data)\n",
        "  references.append(target_sent)\n",
        "  hypotheses.append(\"<start> \" + translation)\n",
        "  \n",
        "results = sacrebleu.raw_corpus_bleu(hypotheses, [references])\n",
        "print(results)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BLEU(score=53.457128343533576, counts=[13812, 9304, 6899, 5408], totals=[18727, 16727, 14727, 12727], precisions=[73.75447215250708, 55.622646021402524, 46.845929245603315, 42.492339121552604], bp=1.0, sys_len=18727, ref_len=18486)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5lY_yETe0JlZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Looks like we got a relatively decent score BLEAU of **54** on the training set. It is important to mention that since we assignment did not specify, I did not apply the model on a hidden test set."
      ]
    },
    {
      "metadata": {
        "id": "1qVg9k7hPjzt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# saving the results\n",
        "input_text, targets, translations = [], [], []\n",
        "\n",
        "for i in range(len(sentences)):\n",
        "  input_sent, target_sent, translation = translate(sentences, source_data, idx=i)\n",
        "  targets.append(target_sent)\n",
        "  input_text.append(input_sent)\n",
        "  translations.append(\"<start> \" + translation)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "q2h-ru59QnwF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "61a0fdfb-a0ed-4196-e5ac-9dc469f1dc5f"
      },
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(input_text, columns=['input'])\n",
        "df['target'] = targets\n",
        "df['translation'] = translations\n",
        "df.to_csv('eng_to_spa.csv')\n",
        "df.head()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>input</th>\n",
              "      <th>target</th>\n",
              "      <th>translation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>&lt;start&gt; For more information , visit our websi...</td>\n",
              "      <td>&lt;start&gt; Para mas informacion , visite nuestro ...</td>\n",
              "      <td>&lt;start&gt; para mas informacion , visite nuestro ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>&lt;start&gt; When in Rome , do as the Romans do . &lt;...</td>\n",
              "      <td>&lt;start&gt; Alla donde fueres , haz lo que vieres ...</td>\n",
              "      <td>&lt;start&gt; alla donde fueres , haz lo que vieres ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>&lt;start&gt; This song s in the key of G . &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; Esta cancion esta en clave de sol . &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; esta cancion esta en clave de sol . &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>&lt;start&gt; I ll always love you . &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; Siempre te amare . &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; siempre te amare . &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>&lt;start&gt; I would like to repay your kindness in...</td>\n",
              "      <td>&lt;start&gt; Me gustaria compensar su gentileza ape...</td>\n",
              "      <td>&lt;start&gt; me gustaria compensar su gentileza ape...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               input  \\\n",
              "0  <start> For more information , visit our websi...   \n",
              "1  <start> When in Rome , do as the Romans do . <...   \n",
              "2        <start> This song s in the key of G . <end>   \n",
              "3               <start> I ll always love you . <end>   \n",
              "4  <start> I would like to repay your kindness in...   \n",
              "\n",
              "                                              target  \\\n",
              "0  <start> Para mas informacion , visite nuestro ...   \n",
              "1  <start> Alla donde fueres , haz lo que vieres ...   \n",
              "2  <start> Esta cancion esta en clave de sol . <end>   \n",
              "3                   <start> Siempre te amare . <end>   \n",
              "4  <start> Me gustaria compensar su gentileza ape...   \n",
              "\n",
              "                                         translation  \n",
              "0  <start> para mas informacion , visite nuestro ...  \n",
              "1  <start> alla donde fueres , haz lo que vieres ...  \n",
              "2  <start> esta cancion esta en clave de sol . <end>  \n",
              "3                   <start> siempre te amare . <end>  \n",
              "4  <start> me gustaria compensar su gentileza ape...  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "metadata": {
        "id": "UqtWCSb00dJD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Looking at the resulting dataframe above, we can see that the translation is relatively accurate and captures most of the context."
      ]
    },
    {
      "metadata": {
        "id": "aBclZfIhTjyV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('eng_to_spa.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XLlQEH4Of6cx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Spanish to English Model\n",
        "Here, we will train a second model to translate between the same two languages in reverse order."
      ]
    },
    {
      "metadata": {
        "id": "QVd09HKyf7ih",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# pulling the data again \n",
        "# convering the dataframe into a list representation\n",
        "sentences2 = data_sub.values.tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8RIz8I5S0oie",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Using the same data but flipping between targets and sources to reverse the languages. Next, we are following the same logic as in the previous task."
      ]
    },
    {
      "metadata": {
        "id": "-I8tLiBOTt-2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "outputId": "8bfd9a96-c07f-4871-90f9-c3ff2e2b9c8f"
      },
      "cell_type": "code",
      "source": [
        "print(\"Original:\", sentences2[0])\n",
        "sentences2 = [(preprocess(target), preprocess(source)) for (source, target) in sentences2]\n",
        "print(\"Preprocessed:\", sentences2[0])"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original: ['For more information, visit our website.', 'Para más información, visite nuestro sitio.']\n",
            "Preprocessed: ('<start> Para mas informacion , visite nuestro sitio . <end>', '<start> For more information , visit our website . <end>')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XTHPukBjUDit",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# creating a target and source zip view\n",
        "source_sentences2, target_sentences2 = list(zip(*sentences2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JoFm3SGtUDq1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "94afba21-2507-4168-d4dc-07212b129594"
      },
      "cell_type": "code",
      "source": [
        "# fitting tokenization\n",
        "source_tokenizer2 = tf.keras.preprocessing.text.Tokenizer(filters='', oov_token='outofvocab')\n",
        "source_tokenizer2.fit_on_texts(source_sentences2)\n",
        "source_data2 = source_tokenizer2.texts_to_sequences(source_sentences2)\n",
        "print(\"Sequence:\", source_data2[0])\n",
        "# adding some padding\n",
        "source_data2 = tf.keras.preprocessing.sequence.pad_sequences(source_data2, padding='post')\n",
        "print(\"Padded:\", source_data2[0])"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequence: [2, 30, 31, 637, 20, 445, 186, 368, 4, 3]\n",
            "Padded: [  2  30  31 637  20 445 186 368   4   3   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CQZMB6y3UnMB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# do the same with target\n",
        "target_tokenizer2 = tf.keras.preprocessing.text.Tokenizer(filters='', oov_token='outofvocab')\n",
        "target_tokenizer2.fit_on_texts(target_sentences2)\n",
        "target_data2 = target_tokenizer2.texts_to_sequences(target_sentences2)\n",
        "target_data2 = tf.keras.preprocessing.sequence.pad_sequences(target_data2, padding='post')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "65yKNssRU1j-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "ce78c7c1-f816-4e76-d7c6-ad2416554379"
      },
      "cell_type": "code",
      "source": [
        "# Create labels for the decoder by shifting the target sequence\n",
        "# one to the right.\n",
        "target_labels2 = np.zeros(target_data2.shape)\n",
        "target_labels2[:,0:target_data2.shape[1] -1] = target_data2[:,1:]\n",
        "\n",
        "print(\"Target sequence\", target_data2[0])\n",
        "print(\"Target label\", target_labels2[0])"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Target sequence [  2  29  76 639  21 286 112 966   4   3   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            "Target label [ 29.  76. 639.  21. 286. 112. 966.   4.   3.   0.   0.   0.   0.   0.\n",
            "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "   0.   0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "P_pVWfNzWc6o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "source_vocab_size2 = len(source_tokenizer2.word_index) + 1\n",
        "target_vocab_size2 = len(target_tokenizer2.word_index) + 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0vrtMXyWVS3V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f73e1046-9292-4f22-af2b-a68eeadb90af"
      },
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "dataset2 = tf.data.Dataset.from_tensor_slices((source_data2, target_data2, target_labels2)).batch(batch_size)\n",
        "# looking at a specific example\n",
        "example_batch = next(iter(dataset2))\n",
        "source, target, taget_labels = example_batch\n",
        "print(\"Shapes:\", source.shape, target.shape, taget_labels.shape)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shapes: (16, 29) (16, 30) (16, 30)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JVuK6U1B01O_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We are using the same model parameters for this task as well for it to be an apples-to-apples comparison between this and the English model."
      ]
    },
    {
      "metadata": {
        "id": "q9umhhY5VpIv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# choosing our parameters\n",
        "embedding_size = 256\n",
        "rnn_size = 128"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ujYoXjmdQuAd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Encoder2(tf.keras.Model):\n",
        "  def __init__(self):\n",
        "    super(Encoder2, self).__init__()\n",
        "    \n",
        "    self.embedding = tf.keras.layers.Embedding(source_vocab_size2,\n",
        "                                               embedding_size)\n",
        "    self.gru = tf.keras.layers.GRU(rnn_size, \n",
        "                                   return_sequences=True, \n",
        "                                   return_state=True)\n",
        "    \n",
        "  def call(self, x, hidden):\n",
        "    x = self.embedding(x)\n",
        "    output, state = self.gru(x, initial_state=hidden)        \n",
        "    return output, state\n",
        "  \n",
        "  def init_state(self, batch_size):\n",
        "    return tf.zeros((batch_size, rnn_size))\n",
        "  \n",
        "class Decoder2(tf.keras.Model):\n",
        "  def __init__(self):\n",
        "    super(Decoder2, self).__init__()\n",
        "    self.embedding = tf.keras.layers.Embedding(target_vocab_size2, \n",
        "                                               embedding_size)\n",
        "    self.gru = tf.keras.layers.GRU(rnn_size, \n",
        "                                   return_sequences=True, \n",
        "                                   return_state=True)\n",
        "\n",
        "    self.dense = tf.keras.layers.Dense(target_vocab_size2)\n",
        "\n",
        "\n",
        "  def call(self, x, hidden):\n",
        "    x = self.embedding(x)\n",
        "    output, state = self.gru(x, initial_state=hidden)\n",
        "    logits = self.dense(output)\n",
        "    return logits, state"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5PFuuOltWNv5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "f22c03f1-e6d8-4d80-c2cf-705daeb6f622"
      },
      "cell_type": "code",
      "source": [
        "# Create a batch of one sentence\n",
        "ex_sentence = tf.expand_dims(source_data2[0], axis=0)\n",
        "ex_translation = tf.expand_dims(target_data2[0], axis=0)\n",
        "ex_labels = tf.expand_dims(target_labels2[0], axis=0)\n",
        "print(ex_sentence.shape)\n",
        "\n",
        "encoder2 = Encoder2()\n",
        "hidden_state = encoder2.init_state(batch_size=1)\n",
        "print(hidden_state.shape)\n",
        "\n",
        "output, hidden_state = encoder2(ex_sentence, hidden_state)\n",
        "print(output.shape)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 29)\n",
            "(1, 128)\n",
            "(1, 29, 128)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Op6xFe3JWNzu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7b6fe3e4-71aa-4daa-bdcc-f1e52dfbf78a"
      },
      "cell_type": "code",
      "source": [
        "# calling the decoder\n",
        "decoder2 = Decoder2()\n",
        "decoder_output, decoder_state = decoder2(ex_labels, hidden_state)\n",
        "print(decoder_output.shape)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 30, 2088)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3SZxcQm6Wth6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f233aef4-bd2f-40ce-ac38-d1aa141d74bf"
      },
      "cell_type": "code",
      "source": [
        "crossentropy = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "def calc_loss(targets, logits):\n",
        "  mask = tf.math.logical_not(tf.math.equal(targets, 0))\n",
        "  mask = tf.cast(mask, dtype=tf.int64)\n",
        "  return crossentropy(targets, logits, sample_weight=mask)\n",
        "\n",
        "print(\"Loss\", calc_loss(ex_labels, decoder_output))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss tf.Tensor(2.2935064, shape=(), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tjAMNsfxXjZX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "21e12588-4fe6-4d55-9fcb-91f414c2fa1f"
      },
      "cell_type": "code",
      "source": [
        "# defining a new translation\n",
        "def translate2(sentences2, source_data2, idx=None):\n",
        "  \n",
        "    if idx == None: \n",
        "      idx = np.random.choice(len(sentences2))\n",
        "    \n",
        "    input_sent = source_data2[idx]\n",
        "    input_sent = tf.expand_dims(input_sent, axis=0)\n",
        "    \n",
        "    hidden_state = encoder2.init_state(batch_size=1)\n",
        "    output, hidden_state = encoder2(input_sent, hidden_state)\n",
        "    \n",
        "    decoder_input = tf.expand_dims([target_tokenizer2.word_index['<start>']], 0)\n",
        "    out_words = []\n",
        "    \n",
        "    decoder_state = hidden_state\n",
        "\n",
        "    while True:\n",
        "      \n",
        "        decoder_output, decoder_state = decoder2(decoder_input, decoder_state)\n",
        "        decoder_input = tf.argmax(decoder_output, -1)\n",
        "        word_idx = decoder_input.numpy()[0][0]\n",
        "        # if we've predicted 0 (which is reserved, usually this will only happen\n",
        "        # before the decoder is trained, just stop translating and return\n",
        "        # what we have)\n",
        "        if word_idx == 0: \n",
        "          out_words.append('<end>')\n",
        "        else:\n",
        "          out_words.append(target_tokenizer2.index_word[word_idx])\n",
        "\n",
        "        if out_words[-1] == '<end>' or len(out_words) >= 20:\n",
        "          break\n",
        "          \n",
        "    translation = ' '.join(out_words)    \n",
        "    return sentences2[idx][0], sentences2[idx][1], translation\n",
        "  \n",
        "\n",
        "input_sent, target_sent, translation = translate2(sentences2, source_data2)\n",
        "print(\"Input: %s\\nTarget: %s\\nTranslation: %s\\n\" % (input_sent, target_sent, translation))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: <start> Ayer fui a nadar al rio . <end>\n",
            "Target: <start> I went to swim in the river yesterday . <end>\n",
            "Translation: egg swim modern silk enjoying behind modest commanding smelled paris thought green theft injured golf draw floor floor disobey floor\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "AW50ALcWXVCx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.Adam()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rT7vSAy2RwXk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "@tf.function # remove this annotation when debugging\n",
        "def train_step2(source_seq, target_seq, target_labels, initial_state):\n",
        "  \n",
        "  with tf.GradientTape() as tape:\n",
        "    encoder_output, encoder_state = encoder2(source_seq, initial_state)\n",
        "    logits, decoder_state = decoder2(target_seq, encoder_state)\n",
        "    loss = calc_loss(target_labels, logits)\n",
        "\n",
        "  variables = encoder2.trainable_variables + decoder2.trainable_variables\n",
        "  gradients = tape.gradient(loss, variables)\n",
        "  optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "  return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "njGJlTkuYHTl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 952
        },
        "outputId": "47a82ae7-55b6-48b9-f03a-8251893733c3"
      },
      "cell_type": "code",
      "source": [
        "EPOCHS = 101\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    start = time.time()\n",
        "  \n",
        "    en_initial_states = encoder2.init_state(batch_size)\n",
        "    \n",
        "    for batch, (source_seq, target_seq, target_labels) in enumerate(dataset2):\n",
        "      loss = train_step2(source_seq, target_seq, target_labels, en_initial_states)\n",
        "      elapsed = time.time() - start\n",
        "    \n",
        "    if epoch % 10 == 0:\n",
        "      print(\"Epoch #%d, Loss %.4f, Time %.2f sec\" % (epoch, loss, elapsed))\n",
        "      input_sent, target_sent, translation = translate2(sentences2, source_data2)\n",
        "      print(\"Input: %s\\nTarget: %s\\nTranslation: %s\\n\" % (input_sent, target_sent, translation))"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch #0, Loss 1.4276, Time 21.95 sec\n",
            "Input: <start> Dejale que pague . <end>\n",
            "Target: <start> Let him pay for it . <end>\n",
            "Translation: i i the <end>\n",
            "\n",
            "Epoch #10, Loss 0.8836, Time 17.81 sec\n",
            "Input: <start> El tren llego con retraso por culpa de la nieve . <end>\n",
            "Target: <start> Owing to the snow , the train was delayed . <end>\n",
            "Translation: i m not a lot of the city . <end>\n",
            "\n",
            "Epoch #20, Loss 0.6167, Time 17.65 sec\n",
            "Input: <start> Nadie me esta escuchando . <end>\n",
            "Target: <start> No one is listening to me . <end>\n",
            "Translation: i m not a lot of rain in . <end>\n",
            "\n",
            "Epoch #30, Loss 0.4590, Time 17.90 sec\n",
            "Input: <start> Ahora esta leyendo una novela . <end>\n",
            "Target: <start> He s reading a novel now . <end>\n",
            "Translation: i m not as stupid as you as the party . <end>\n",
            "\n",
            "Epoch #40, Loss 0.3767, Time 17.75 sec\n",
            "Input: <start> ¿ Esto es lo que quereis ? <end>\n",
            "Target: <start> Is this what you want ? <end>\n",
            "Translation: i m not as stupid as you as tom s in your hand . <end>\n",
            "\n",
            "Epoch #50, Loss 0.2688, Time 17.89 sec\n",
            "Input: <start> A mi no me suena estupido . <end>\n",
            "Target: <start> That doesn t sound stupid to me . <end>\n",
            "Translation: you can t learn a language without making mistakes . <end>\n",
            "\n",
            "Epoch #60, Loss 0.1479, Time 17.72 sec\n",
            "Input: <start> Mary fue secuestrada por piratas . <end>\n",
            "Target: <start> Mary was kidnapped by pirates . <end>\n",
            "Translation: mary has received several prizes for her poetry . <end>\n",
            "\n",
            "Epoch #70, Loss 0.0852, Time 17.77 sec\n",
            "Input: <start> No te preocupes por eso . <end>\n",
            "Target: <start> Don t worry about that . <end>\n",
            "Translation: don t worry about that . <end>\n",
            "\n",
            "Epoch #80, Loss 0.0411, Time 17.38 sec\n",
            "Input: <start> Escribi tres cartas anoche . <end>\n",
            "Target: <start> I wrote three letters last night . <end>\n",
            "Translation: i wrote three letters last night . <end>\n",
            "\n",
            "Epoch #90, Loss 0.0168, Time 17.68 sec\n",
            "Input: <start> Tu eres responsable por la muerte del nino . <end>\n",
            "Target: <start> You are responsible for the death of the child . <end>\n",
            "Translation: you are responsible for the death of the child . <end>\n",
            "\n",
            "Epoch #100, Loss 0.0248, Time 17.52 sec\n",
            "Input: <start> ¿ Podrias dibujarme un mapa ? <end>\n",
            "Target: <start> Could you draw a map for me ? <end>\n",
            "Translation: could you get over for lunch ? the news . <end>\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6M58eF0xYmLU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "ea041d31-b4c5-40c5-94ad-dcead5bb37f4"
      },
      "cell_type": "code",
      "source": [
        "# calculating BLEAU score\n",
        "references2, hypotheses2 = [], []\n",
        "\n",
        "for i in range(len(sentences2)):\n",
        "  input_sent, target_sent, translation = translate2(sentences2, source_data2)\n",
        "  references2.append(target_sent)\n",
        "  hypotheses2.append(\"<start> \" + translation)\n",
        "  \n",
        "results2 = sacrebleu.raw_corpus_bleu(hypotheses2, [references2])\n",
        "print(results2)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BLEU(score=65.09860706495068, counts=[16120, 11541, 9184, 7278], totals=[19336, 17336, 15336, 13336], precisions=[83.3678113363674, 66.57245039224735, 59.88523735002608, 54.57408518296341], bp=0.9975206624286667, sys_len=19336, ref_len=19384)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vEMSru6XBQdg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We are getting yet another decent BLEAU score of **61** (similar to the English model developed)."
      ]
    },
    {
      "metadata": {
        "id": "bOpP8Sbv66QV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# saving the results\n",
        "input_text2, targets2, translations2 = [], [], []\n",
        "\n",
        "for i in range(len(sentences2)):\n",
        "  input_sent, target_sent, translation = translate2(sentences2, source_data2, i)\n",
        "  targets2.append(target_sent)\n",
        "  input_text2.append(input_sent)\n",
        "  translations2.append(\"<start> \" + translation)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "w5R8m3w77Jla",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df2 = pd.DataFrame(input_text2, columns=['input'])\n",
        "df2['target'] = targets2\n",
        "df2['translation'] = translations2\n",
        "df2.to_csv('spa_to_eng.csv')\n",
        "df2.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NU_FFgrj7VRo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('spa_to_eng.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dJ1VltDAf98F",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Playing with back-translation\n",
        "Using the two models to translate a sentence from English to Spanish, and then\n",
        "back to English."
      ]
    },
    {
      "metadata": {
        "id": "kS0A55hbdH_O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "56b4078d-94b5-4f3b-e7fe-620de332b9a5"
      },
      "cell_type": "code",
      "source": [
        "# USING ENGLISH TO SPANISH MODEL\n",
        "# translating a random sentence form a test set \n",
        "input_sent, target_sent, translation_test = translate(sentences_test, source_data_test, idx=560)\n",
        "print(\"Input: %s\\nTarget: %s\\nTranslation: %s\\n\" % (input_sent, target_sent, translation_test))"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: <start> Tom wrote some country songs . <end>\n",
            "Target: <start> Tom escribio unas canciones country . <end>\n",
            "Translation: tom bebio un sorbo de su trago y puso el vaso de vuelta en la mesa . <end>\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ibWYFfXvfwFK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "a7da7e60-25a8-4ac1-97cd-8eab72f45fa8"
      },
      "cell_type": "code",
      "source": [
        "# USING SPANISH TO ENGLISH MODEL\n",
        "# running quick pre-processing on the translated sentence\n",
        "translation_test_ex = 'quiero matar a alguien.'\n",
        "target_test_ex = 'I want your opinion'\n",
        "sentences_ex = [[translation_test_ex, target_test_ex]]\n",
        "sentences_ex = [(preprocess(source), preprocess(target)) for (source, target) in sentences_ex]\n",
        "source_sentences_ex, target_sentences_ex = list(zip(*sentences_ex))\n",
        "source_data_ex = source_tokenizer2.texts_to_sequences(source_sentences_ex)\n",
        "source_data_ex = tf.keras.preprocessing.sequence.pad_sequences(source_data_ex, padding='post')\n",
        "\n",
        "# translating the resulting sentence back into English\n",
        "input_sent, target_sent, translation_test = translate2(sentences_ex, source_data_ex, idx=0)\n",
        "print(\"Input: %s\\nTarget: %s\\nTranslation: %s\\n\" % (input_sent, target_sent, translation_test))"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: <start> quiero matar a alguien . <end>\n",
            "Target: <start> I want your opinion <end>\n",
            "Translation: i want to be alone ! <end>\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3aGbRbF7CWYc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Looking at a single sentence expriment, the results of back-transaltion are not very good. The final sentence does not capture the original very well! Let us see how bad the score is when working with 1000 sentences."
      ]
    },
    {
      "metadata": {
        "id": "-29xsVPSeEKb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# USING ENGLISH TO SPANISH MODEL\n",
        "# translating the entire test corpus\n",
        "input_text_test1, targets_test1, translations_test1 = [], [], []\n",
        "\n",
        "for i in range(len(sentences_test)):\n",
        "  input_sent, target_sent, translation = translate(sentences_test, source_data_test, idx=i)\n",
        "  targets_test1.append(target_sent)\n",
        "  input_text_test1.append(input_sent)\n",
        "  translations_test1.append(\"<start> \" + translation)\n",
        "  \n",
        "df_test = pd.DataFrame(input_text_test1, columns=['input'])\n",
        "df_test['target'] = targets_test1\n",
        "df_test['translation'] = translations_test1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vbNX3LpYksvT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df_test.to_csv('eng2spa_test.csv')\n",
        "df_test.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YaqWIkqMk2Ut",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('eng2spa_test.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6-g4gURtl-I-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# running necessary preprocessing\n",
        "sentences_test = df_test[['translation', 'input']]\n",
        "sentences_test = [tuple(x) for x in sentences_test.values]\n",
        "source_sentences_test, target_sentences_test = list(zip(*sentences_test))\n",
        "source_data_test = source_tokenizer2.texts_to_sequences(source_sentences_test)\n",
        "source_data_test = tf.keras.preprocessing.sequence.pad_sequences(source_data_test, padding='post')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "25r06VMsp6Eb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7f3c9040-0984-4a50-9369-ab59b6e4b498"
      },
      "cell_type": "code",
      "source": [
        "# calculating BLEAU score\n",
        "references3, hypotheses3 = [], []\n",
        "\n",
        "for i in range(len(sentences_test)):\n",
        "  input_sent, target_sent, translation = translate2(sentences_test, source_data_test)\n",
        "  references2.append(target_sent)\n",
        "  hypotheses2.append(\"<start> \" + translation)\n",
        "  \n",
        "results3 = sacrebleu.raw_corpus_bleu(hypotheses3, [references3])\n",
        "print(results3)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BLEU(score=0.0, counts=[0, 0, 0, 0], totals=[0, 0, 0, 0], precisions=[0, 0, 0, 0], bp=1.0, sys_len=0, ref_len=0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "r9ibA45VCqY3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "As expected, the score has dropped quite a bit (now down to **~0**) when working with back-translation:(. This is to be expected since we are now trying to translate a translated sentence which is a much harder task."
      ]
    },
    {
      "metadata": {
        "id": "01LNCoHmb55S",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}